{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Sentiment Analysis\n",
            "\n",
            "### ECE590 Homework assignment 2\n",
            "Name: Javier Cervantes\n",
            "net id: jc1010\n",
            "\n",
            "We are interested in sentiment analysis. Given a short document, we wish to assess whether the corresponding sentiment is positive (label ùë¶=1 ) or negative (label ùë¶=0). The assignment is as follows: \n",
            "\n",
            "1. For every word, we will learn a corresponding d-dimensional vector $x_i \\in \\mathbb{R}^d$ for word $i$ in the vocabulary. \n",
            "\n",
            "2. Assume that there are $M_j$ words in document $j$. The feature vector for this document is $f_j = \\frac{1}{M_j} \\sum_{i=1}^{M_j} x_{(m, j)}$ such that $x_{(m, j)}$ is the d-dimensional vector for the m-th word in document j.\n",
            "\n",
            "3. The probability of positive sentiment for document j is modeled as $P(y_j = 1 | f_j) = \\sigma[w \\cdot f_j + b]$ where $\\sigma$ is the sigmoid function, $w \\in \\mathbb{R}^d$ is the weight vector and $b \\in \\mathbb{R}$ is the bias."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 74,
         "metadata": {},
         "outputs": [],
         "source": [
            "from datasets import load_dataset\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "import torch.optim as optim\n",
            "import torchtext\n",
            "import nltk\n",
            "from nltk.corpus import stopwords\n",
            "from datasets import load_from_disk\n",
            "import numpy as np\n",
            "import tqdm\n",
            "import pandas as pd\n",
            "from datasets import Dataset\n",
            "import collections\n",
            "from sklearn.metrics import confusion_matrix\n",
            "import seaborn as sns\n",
            "import matplotlib.pyplot as plt"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "seed = 257\n",
            "\n",
            "np.random.seed(seed)\n",
            "torch.manual_seed(seed)\n",
            "torch.cuda.manual_seed(seed)\n",
            "torch.backends.cudnn.deterministic = True"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Prepare the data\n",
            "\n",
            "We begin by tokenizing and cleaning the text. In this process, we'll remove punctuation, convert to lowercase, and remove stopwords. I believe that it's worth noting that removing stop words might be problematic in some model designs. For this particular model, which doesn't take into account word order, removing words like \"not\" should not affect the model's performance because the model won't have the capability of identifying where upon a given document the word \"not\" is located."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "# load the dataset\n",
            "train_data, test_data = load_dataset(\"yelp_polarity\", split=[\"train\", \"test\"])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# tokenize the dataset\n",
            "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
            "\n",
            "\n",
            "def tokenize(obs, tokenizer, max_length):\n",
            "    \"\"\"\n",
            "    Tokenize an observation\n",
            "    max_length: the maximum length of the tokenized sequence\n",
            "    \"\"\"\n",
            "    return {\"tokens\": tokenizer(obs[\"text\"])[:max_length]}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "# remove stopwords and punctuation\n",
            "stop_words = stopwords.words(\"english\")\n",
            "\n",
            "\n",
            "def remove_stopwords(obs):\n",
            "    \"\"\"\n",
            "    Removes stopwords from tokens for each obs in Dataset\n",
            "    \"\"\"\n",
            "    obs[\"tokens\"] = [word for word in obs[\"tokens\"] if word not in stop_words]\n",
            "    return obs\n",
            "\n",
            "\n",
            "def remove_punctuation(obs):\n",
            "    \"\"\"\n",
            "    Removes punctuation from tokens for each obs in Dataset\n",
            "    \"\"\"\n",
            "    obs[\"tokens\"] = [word for word in obs[\"tokens\"] if word.isalpha()]\n",
            "    return obs\n",
            "\n",
            "\n",
            "def tokenize_and_clean(obs, max_length):\n",
            "    \"\"\"\n",
            "    Tokenize, remove stopwords and punctuation from observation\n",
            "    \"\"\"\n",
            "    tokens = tokenizer(obs[\"text\"][:max_length])\n",
            "    tokens = [word for word in tokens if word not in stop_words]\n",
            "    tokens = [word for word in tokens if word.isalpha()]\n",
            "    return {\"tokens\": tokens}\n",
            "\n",
            "\n",
            "# train_data = train_data.map(remove_stopwords)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Working under the assumption that a document's sentiment can be identified rather quickly, I've set the maximum length of a document to 100 words. This is a hyperparameter that can be adjusted to improve the model's performance."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 60,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "27219af5f64d4571be701a7532e5097e",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Map:   0%|          | 0/38000 [00:00<?, ? examples/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "max_length = 100\n",
            "\n",
            "train_data = train_data.map(tokenize_and_clean, fn_kwargs={\"max_length\": max_length})\n",
            "test_data = test_data.map(tokenize_and_clean, fn_kwargs={\"max_length\": max_length})"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now that our data has been tokenized and cleaned, we can create a validation set."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "# validation data\n",
            "train_valid_data = train_data.train_test_split(test_size=0.25)\n",
            "train_data = train_valid_data[\"train\"]\n",
            "valid_data = train_valid_data[\"test\"]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "From the training data, we now proceed to create a vocabulary comprised of the training data's unique words. Given the large number of documents in the training set, I'll add a minimum frequency threshold of 30 for every word to be included in the vocabulary. Given the large number of observations we have available, removing words that appear only a few times should not affect the model's performance.\n",
            "\n",
            "Also very important in the creation of our vocabulary is to add a couple of special tokens: one for padding and one for unknown words. The padding token will be used to make all documents the same length, and the unknown token will be used to catch words that are not in the vocabulary."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "7827"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# creating the vocabulary\n",
            "special_tokens = [\"<unk>\", \"<pad>\"]\n",
            "\n",
            "# setting a minimum frequency for the tokens ... 30 times in 420,000 sentences is not a lot\n",
            "vocab = torchtext.vocab.build_vocab_from_iterator(\n",
            "    train_data[\"tokens\"], specials=special_tokens, min_freq=30\n",
            ")\n",
            "vocab.set_default_index(vocab[\"<unk>\"])\n",
            "len(vocab)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We now have a vocabulary of 7,827 unique words (including the special tokens). The Vocab object has a method that is used to identify unknown words and replace them with the unknown token. We utilize that method to assign the index of \"unk\".\n",
            "\n",
            "Now that we have the vocabulary, we can numerically encode the words in the data using indices from the vocabulary we just created. We also need to pad the sequences so that they're all the same length and we don't run into issues when inputting them into the model."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 61,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "0dfbed0e44a14e0cb36361b8be4f5928",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Map:   0%|          | 0/38000 [00:00<?, ? examples/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "def numericalize_example(obs, vocab):\n",
            "    ids = vocab.lookup_indices(obs[\"tokens\"])\n",
            "    return {\"ids\": ids}\n",
            "\n",
            "\n",
            "train_data = train_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
            "valid_data = valid_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
            "test_data = test_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 62,
         "metadata": {},
         "outputs": [],
         "source": [
            "train_data = train_data.with_format(\"torch\", columns=[\"ids\", \"label\"])\n",
            "valid_data = valid_data.with_format(\"torch\", columns=[\"ids\", \"label\"])\n",
            "test_data = test_data.with_format(\"torch\", columns=[\"ids\", \"label\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We're going to make use of data loaders. This will allow us to load the data in batches, which will be useful for training the model. This is where we'll use the padding process mentioned above. In this process we need to adequately structure the data so that it can be input into the model. We'll make use of a collate function to do this. Since we're working with PyTorch, we'll create a single tensor for each batch of data and a single tensor for the labels. Note that the data tensor will have a shape of (batch_size, max_length) and the labels tensor will have a shape of (batch_size, 1)."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "pad_index = vocab[\"<pad>\"]\n",
            "\n",
            "\n",
            "def get_collate_fn(pad_index):\n",
            "    def collate_fn(batch):\n",
            "        batch_ids = [doc[\"ids\"] for doc in batch]\n",
            "        batch_ids = nn.utils.rnn.pad_sequence(\n",
            "            batch_ids, padding_value=pad_index, batch_first=True\n",
            "        )\n",
            "        batch_labels = [doc[\"label\"] for doc in batch]\n",
            "        batch_labels = torch.stack(batch_labels)\n",
            "        return {\"ids\": batch_ids, \"label\": batch_labels}\n",
            "\n",
            "    return collate_fn\n",
            "\n",
            "\n",
            "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
            "    collate_fn = get_collate_fn(pad_index)\n",
            "    data_loader = torch.utils.data.DataLoader(\n",
            "        dataset=dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=shuffle\n",
            "    )\n",
            "    return data_loader"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now we shall set the batch size and create the data loaders for the training, validation and test sets."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 63,
         "metadata": {},
         "outputs": [],
         "source": [
            "batch_size = 256\n",
            "\n",
            "train_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
            "valid_loader = get_data_loader(valid_data, batch_size, pad_index, shuffle=False)\n",
            "test_loader = get_data_loader(test_data, batch_size, pad_index, shuffle=False)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Building the model\n",
            "\n",
            "We begin by defining an Embedding layer. Knowing full well that modern NLP models have multiple features, I'll posit that the features required for sentiment analysis are not as complex as those required for other tasks. For that reason, I'll set the embedding dimension to 20. This is a hyperparameter that can be adjusted to improve the model's performance."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "class Sentiment(nn.Module):\n",
            "    def __init__(self, vocab_size, embed_dim, pad_index):\n",
            "        super(Sentiment, self).__init__()\n",
            "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_index)\n",
            "        self.fc = nn.Linear(embed_dim, 2)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.embedding(x)\n",
            "        x = x.mean(dim=1)\n",
            "        x = torch.tanh(x)\n",
            "        x = self.fc(x)\n",
            "\n",
            "        return x"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [],
         "source": [
            "vocab_size = len(vocab)\n",
            "embed_dim = 20\n",
            "\n",
            "model = Sentiment(vocab_size, embed_dim, pad_index)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [],
         "source": [
            "# loss function and optimizer\n",
            "criterion = nn.CrossEntropyLoss()\n",
            "optimizer = optim.Adam(model.parameters(), lr=0.001)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "cpu\n"
               ]
            }
         ],
         "source": [
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(device)\n",
            "model = model.to(device)\n",
            "criterion = criterion.to(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 64,
         "metadata": {},
         "outputs": [],
         "source": [
            "# training the model\n",
            "def train(data_loader, model, criterion, optimizer, device):\n",
            "    model.train()\n",
            "    epoch_losses = []\n",
            "    epoch_accuracies = []\n",
            "    for batch in tqdm.tqdm(data_loader, desc=\"Training...\"):\n",
            "        ids = batch[\"ids\"].to(device)\n",
            "        label = batch[\"label\"].to(device)\n",
            "        prediction = model(ids)\n",
            "        loss = criterion(prediction, label)\n",
            "        accuracy = (prediction.argmax(1) == label).sum().item() / len(label)\n",
            "        optimizer.zero_grad()\n",
            "        loss.backward()\n",
            "        optimizer.step()\n",
            "        epoch_losses.append(loss.item())\n",
            "        epoch_accuracies.append(accuracy)\n",
            "    return np.mean(epoch_losses), np.mean(epoch_accuracies)\n",
            "\n",
            "\n",
            "# validation\n",
            "def evaluate(data_loader, model, criterion, device):\n",
            "    model.eval()\n",
            "    epoch_losses = []\n",
            "    epoch_accuracies = []\n",
            "    with torch.no_grad():\n",
            "        for batch in tqdm.tqdm(data_loader, desc=\"Evaluating...\"):\n",
            "            ids = batch[\"ids\"].to(device)\n",
            "            label = batch[\"label\"].to(device)\n",
            "            prediction = model(ids)\n",
            "            loss = criterion(prediction, label)\n",
            "            accuracy = (prediction.argmax(1) == label).sum().item() / len(label)\n",
            "            epoch_losses.append(loss.item())\n",
            "            epoch_accuracies.append(accuracy)\n",
            "    return np.mean(epoch_losses), np.mean(epoch_accuracies)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1641/1641 [00:24<00:00, 67.40it/s]\n",
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 547/547 [00:06<00:00, 88.47it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 0\n",
                  "Train Loss: 0.5560, Train Accuracy: 0.7046\n",
                  "Valid Loss: 0.4838, Valid Accuracy: 0.7620\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1641/1641 [00:23<00:00, 70.87it/s]\n",
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 547/547 [00:06<00:00, 89.08it/s] \n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 1\n",
                  "Train Loss: 0.4645, Train Accuracy: 0.7734\n",
                  "Valid Loss: 0.4589, Valid Accuracy: 0.7769\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1641/1641 [00:22<00:00, 71.61it/s]\n",
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 547/547 [00:06<00:00, 87.57it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 2\n",
                  "Train Loss: 0.4480, Train Accuracy: 0.7836\n",
                  "Valid Loss: 0.4520, Valid Accuracy: 0.7808\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1641/1641 [00:23<00:00, 70.30it/s]\n",
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 547/547 [00:06<00:00, 87.23it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 3\n",
                  "Train Loss: 0.4415, Train Accuracy: 0.7879\n",
                  "Valid Loss: 0.4495, Valid Accuracy: 0.7823\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1641/1641 [00:23<00:00, 70.37it/s]\n",
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 547/547 [00:06<00:00, 86.75it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 4\n",
                  "Train Loss: 0.4383, Train Accuracy: 0.7898\n",
                  "Valid Loss: 0.4486, Valid Accuracy: 0.7836\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1641/1641 [00:23<00:00, 70.06it/s]\n",
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 547/547 [00:06<00:00, 88.41it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 5\n",
                  "Train Loss: 0.4364, Train Accuracy: 0.7913\n",
                  "Valid Loss: 0.4482, Valid Accuracy: 0.7838\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1641/1641 [00:23<00:00, 70.16it/s]\n",
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 547/547 [00:06<00:00, 84.30it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 6\n",
                  "Train Loss: 0.4353, Train Accuracy: 0.7919\n",
                  "Valid Loss: 0.4482, Valid Accuracy: 0.7836\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1641/1641 [00:24<00:00, 68.36it/s]\n",
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 547/547 [00:06<00:00, 86.23it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 7\n",
                  "Train Loss: 0.4346, Train Accuracy: 0.7924\n",
                  "Valid Loss: 0.4483, Valid Accuracy: 0.7834\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1641/1641 [00:23<00:00, 71.18it/s]\n",
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 547/547 [00:06<00:00, 89.47it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 8\n",
                  "Train Loss: 0.4339, Train Accuracy: 0.7925\n",
                  "Valid Loss: 0.4483, Valid Accuracy: 0.7835\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1641/1641 [00:22<00:00, 72.00it/s]\n",
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 547/547 [00:06<00:00, 86.11it/s]"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 9\n",
                  "Train Loss: 0.4337, Train Accuracy: 0.7926\n",
                  "Valid Loss: 0.4486, Valid Accuracy: 0.7831\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n"
               ]
            }
         ],
         "source": [
            "n_epochs = 10\n",
            "best_valid_loss = float(\"inf\")\n",
            "\n",
            "metrics = collections.defaultdict(list)\n",
            "\n",
            "for epoch in range(n_epochs):\n",
            "    train_loss, train_accuracy = train(\n",
            "        train_loader, model, criterion, optimizer, device\n",
            "    )\n",
            "    valid_loss, valid_accuracy = evaluate(valid_loader, model, criterion, device)\n",
            "    print(f\"Epoch: {epoch}\")\n",
            "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
            "    print(f\"Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n",
            "    print()\n",
            "    metrics[\"train_loss\"].append(train_loss)\n",
            "    metrics[\"train_accuracy\"].append(train_accuracy)\n",
            "    metrics[\"valid_loss\"].append(valid_loss)\n",
            "    metrics[\"valid_accuracy\"].append(valid_accuracy)\n",
            "\n",
            "    if valid_loss < best_valid_loss:\n",
            "        best_valid_loss = valid_loss\n",
            "        torch.save(model.state_dict(), \"best_model.pt\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Model Assesment\n",
            "\n",
            "Now that the validation process has completed, we can assess the model's performance. By design, we stored the model at the point where the training process resulted in the lowest validation loss with the objective of avoiding overfitting. That is the model that we're going to test on our held out test set."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<All keys matched successfully>"
                  ]
               },
               "execution_count": 25,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "model = Sentiment(vocab_size, embed_dim, pad_index)\n",
            "model.load_state_dict(torch.load(\"best_model.pt\"))\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 66,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 149/149 [00:01<00:00, 89.93it/s]"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Test Loss: 0.4440, Test Accuracy: 0.786%\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n"
               ]
            }
         ],
         "source": [
            "test_loss, test_acc = evaluate(test_loader, model, criterion, device)\n",
            "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.3f}%\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 72,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Lists to store the predicted and true labels\n",
            "predicted_labels = []\n",
            "true_labels = []\n",
            "\n",
            "# Iterate over the test data\n",
            "for batch in test_loader:\n",
            "    # Move the data and labels to the same device as your model (if not already)\n",
            "    data = batch[\"ids\"].to(device)\n",
            "    labels = batch[\"label\"].to(device)\n",
            "\n",
            "    # Make a prediction\n",
            "    with torch.no_grad():\n",
            "        outputs = model(data)\n",
            "\n",
            "    # Get the predicted class\n",
            "    _, preds = torch.max(outputs, 1)\n",
            "\n",
            "    # Store the predicted and true labels\n",
            "    predicted_labels.extend(preds.cpu().numpy())\n",
            "    true_labels.extend(labels.cpu().numpy())\n",
            "\n",
            "# Convert the lists to numpy arrays\n",
            "predicted_labels = np.array(predicted_labels)\n",
            "true_labels = np.array(true_labels)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 76,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Text(0.5, 1.0, 'Confusion Matrix')"
                  ]
               },
               "execution_count": 76,
               "metadata": {},
               "output_type": "execute_result"
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 2 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# confusion matrix heatmap with seaborn\n",
            "cm = confusion_matrix(true_labels, predicted_labels)\n",
            "ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
            "ax.set_xlabel(\"Predicted labels\")\n",
            "ax.set_ylabel(\"True labels\")\n",
            "ax.set_title(\"Confusion Matrix\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 89,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Precision: 0.78\n",
                  "Recall: 0.79\n"
               ]
            }
         ],
         "source": [
            "# precision: out of all the predicted positive classes, how many were actually positive\n",
            "precision = np.sum(cm[1, 1]) / (np.sum(cm[1, 1]) + np.sum(cm[0, 1]))\n",
            "print(\"\\nPrecision: {:.2f}\".format(precision))\n",
            "\n",
            "# recall: out of all the actual positive classes, how many were predicted positive\n",
            "recall = np.sum(cm[1, 1]) / (np.sum(cm[1, 1]) + np.sum(cm[1, 0]))\n",
            "print(\"Recall: {:.2f}\".format(recall))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Further considerations\n",
            "\n",
            "One of our objectives was to create word embeddings specific to sentiment analysis. Arguably, we can use the word embeddings learned in this process for sentimen analysis on similar datasets. Let's see a couple of embeddings examples to see if we can extract any insights from them."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 92,
         "metadata": {},
         "outputs": [],
         "source": [
            "# add embeddings to vocab\n",
            "embeddings = model.embedding.weight.detach().cpu().numpy()\n",
            "word_to_embedding = {word: embeddings[i] for word, i in vocab.get_stoi().items()}\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 113,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Comparing fantastic and terrible: -31.67\n",
                  "Comparing fantastic and phenomenal: 19.67\n",
                  "Comparing fantastic and great: 8.23\n",
                  "Comparing fantastic and bad: -11.64\n",
                  "Comparing terrible and bad: 13.10\n",
                  "Comparing fantastic and house: 1.76\n"
               ]
            }
         ],
         "source": [
            "def compare_embeddings(word1, word2):\n",
            "    \"\"\"\n",
            "    Compare the embeddings of two words\n",
            "    \"\"\"\n",
            "    print(\n",
            "        f\"Comparing {word1} and {word2}: {np.dot(word_to_embedding[word1], word_to_embedding[word2]):.2f}\"\n",
            "    )\n",
            "\n",
            "\n",
            "compare_embeddings(\"fantastic\", \"terrible\")\n",
            "compare_embeddings(\"fantastic\", \"phenomenal\")\n",
            "compare_embeddings(\"fantastic\", \"great\")\n",
            "compare_embeddings(\"fantastic\", \"bad\")\n",
            "compare_embeddings(\"terrible\", \"bad\")\n",
            "compare_embeddings(\"fantastic\", \"house\")\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "From the above results we can gather some intuition into some of the relationships that were learned: We would expect that words that convey similar sentiment would have similar embeddings (and therefore a positive dot product). Words that convey sentiment in the same direction but with different intensity would be positive but with a lower dot product. Words that convey sentiment in the opposite direction would have a negative dot product. Finally, comparing a word with sentimental value to a word with no sentimental value should result in a dot product close to zero."
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "base",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.12"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
