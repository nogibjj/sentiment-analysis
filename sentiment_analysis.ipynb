{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Sentiment Analysis\n",
            "\n",
            "### ECE590 Homework assignment 2\n",
            "Name: Javier Cervantes\n",
            "\n",
            "net id: jc1010\n",
            "\n",
            "We are interested in sentiment analysis. Given a short document, we wish to assess whether the corresponding sentiment is positive (label ð‘¦=1 ) or negative (label ð‘¦=0). The assignment is as follows: \n",
            "\n",
            "1. For every word, we will learn a corresponding d-dimensional vector $x_i \\in \\mathbb{R}^d$ for word $i$ in the vocabulary. \n",
            "\n",
            "2. Assume that there are $M_j$ words in document $j$. The feature vector for this document is $f_j = \\frac{1}{M_j} \\sum_{i=1}^{M_j} x_{(m, j)}$ such that $x_{(m, j)}$ is the d-dimensional vector for the m-th word in document j.\n",
            "\n",
            "3. The probability of positive sentiment for document j is modeled as $P(y_j = 1 | f_j) = \\sigma[w \\cdot f_j + b]$ where $\\sigma$ is the sigmoid function, $w \\in \\mathbb{R}^d$ is the weight vector and $b \\in \\mathbb{R}$ is the bias."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We would like to maximize this probability as a function of our parameters. Given independent Bernoulli trials, we can define a likelihood function, $L(p|x)$, as:\n",
            "\n",
            "$$L(w|y, X) = \\prod_{i=1}^N P(y_i|x_i) = \\prod _{i=1}^N P(y = 1 | x_i)^{y_i} P(y_i=0 | x_i)^{1-y_i} = \\prod _{i=1}^N \\sigma(w^T x_i)^{y_i}[1-\\sigma(w^Tx_i)]^{1-y_i};$$\n",
            "\n",
            "where $p$ is the probability of success, $x_i$ is the outcome of the i-th trial, and N is the number of trials.\n",
            "\n",
            "We can rewrite the likelihood function as: \n",
            "\n",
            "$$ log(L(w|y, X)) = \\sum_{i=1}^N y_i log(\\sigma(w^T x_i)) + (1-y_i) log(1-\\sigma(w^T x_i))$$\n",
            "\n",
            "This is called the log-likelihood function. Note that maximizing the log-likelihood is equivalent to minimizing the negative log-likelihood. We shall define our cost function $C(w)$ as the negative log-likelihood function. This function is called the **Cross Entropy Loss Function**:\n",
            "\n",
            "$$C(w) = - \\Big [ \\sum_{i=1}^N y_i log(\\sigma(w^T x_i)) + (1-y_i) log(1-\\sigma(w^T x_i)) \\Big ]; \\\\ \\text{where } \\sigma(w^Tx) = \\frac{1}{1+exp^{-w^Tx}} $$\n",
            "\n",
            "Given that there's no closed-form solution to the minimization of this cost function, we must use another approach."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Gradient Descent\n",
            "\n",
            "Gradient descent involves starting at a random point, evaluating the loss function at that point, then calculating the gradient of the loss function with respect to its parameters. To define the next point, we take a step in the direction opposite to the gradient, scaled by a learning rate:\n",
            "\n",
            "$$ w_{t+1} = w_t - \\alpha \\nabla_{|w_t} C(w)_{|w_t} $$\n",
            "\n",
            "Where $\\alpha$ is the learning rate, and $\\nabla_{|w_t} C(w)$ is the gradient of the cost function at point $w_t$.\n",
            "\n",
            "Given this definition, we face a problem for neural networks with large parameter vectors $w$, wherein the sensitivity of the loss function $L(w)$ varies for each component. This means that having a single learning rate $\\alpha$ for all components of $w$ is far from ideal.\n",
            "\n",
            "To address this issue, we can introduce a $d \\times d$ matrix, $P$, called the preconditioner matrix. One important property of this matrix is that it's positive definite, which means that  $\\nabla _w L(w) \\cdot P \\nabla _w L(w) > 0$ which ensures that each step in the gradient descent process is still taken in the same direction as the previously defined gradient.\n",
            "\n",
            "This leaves us with a modified gradient descent algorithm: $$ w_{t+1} = w_t - \\alpha P \\nabla_{|w_t} C(w)_{|w_t} $$\n",
            "\n",
            "Where $\\alpha$ is the learning rate, and $P$ is the positive definite matrix.\n",
            "\n",
            "RMSprop proposes $P$ such that it scales each gradient in an operation similar to normalization: \n",
            "\n",
            "$$ P_{k} = diag \\Bigg (\\frac{1}{\\lambda + \\sqrt {V_{k}}} \\Bigg); \\\\ \\text{where } V_{k} = \\gamma V_{k-1} + (1-\\gamma) g_k \\odot g_k $$ \n",
            "where $g_k$ is the gradient at iteration k, $\\lambda$ is a small number to avoid division by zero, and $ \\odot $ is the Hadamard product.\n",
            "\n",
            "Choosing such a matrix has an effect on the learning rate such that, for those dimensions that have been move volatile, the learning rate is decreased, and viceversa. This modification is particularly useful for complicated loss functions.\n",
            "\n",
            "One proposed extension of the RMSprop is to also track the mean of the gradient: $m_k = \\gamma_1 m_{k-1} + (1-\\gamma_1) g_k$. This proposed extension allows the convergence process to be more efficient. If the gradient is consistently pointing in the same direction, the learning rate is increased by the average. Alternatively, if the gradient is consistently changing direction, the learning rate is decreased by the average. The updated algorithm is:\n",
            "\n",
            "$$ w_{k+1} = w_k - \\alpha \\frac{m_{k}}{\\sqrt{V_{k} + \\lambda}} $$\n",
            "\n",
            "Upon observing these extensions we can identify a potential issue that arises during the first couple of iterations. Since the moving averages of the mean and variance are initialized to zero, depending on the levels of $\\gamma_1$ and $\\gamma_2$, the value of $m_k$ and $V_k$ can be close to zero. To address this issue, a final extension is proposed: \n",
            "\n",
            "$$ \\hat m_k = \\frac{m_k}{1-\\gamma_1^k} \\text{ and } \\hat V_k = \\frac{V_k}{1-\\gamma_2^k} $$\n",
            "\n",
            "This leads to the final expression of the gradient descent algorithm called **Adam**:\n",
            "\n",
            "$$ w_{k+1} = w_k - \\alpha \\frac{\\hat m_{k}}{\\sqrt{\\hat V_{k} + \\lambda}};$$\n",
            "$$ \\hat m_k = \\frac{m_k}{1-\\gamma_1^k} \\text{ and } \\hat V_k = \\frac{V_k}{1-\\gamma_2^k}; $$\n",
            "$$ m_k = \\gamma_1 m_{k-1} + (1-\\gamma_1) g_k \\text{ and } V_{k} = \\gamma_2 V_{k-1} + (1-\\gamma_2) g_k \\odot g_k; $$\n",
            "\n",
            "\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Sentiment Analysis\n",
            "\n",
            "We will use the process described above to perform sentiment analysis on the `yelp_polarity` dataset. This dataset contains 560,000 training samples and 38,000 testing samples. Each sample is a review of a business, and is labeled as either positive or negative. The dataset is available at: https://huggingface.co/datasets/yelp_polarity."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "from datasets import load_dataset\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.optim as optim\n",
            "import torchtext\n",
            "from nltk.corpus import stopwords\n",
            "import numpy as np\n",
            "import tqdm\n",
            "import collections\n",
            "from sklearn.metrics import confusion_matrix\n",
            "import seaborn as sns"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "seed = 257\n",
            "\n",
            "np.random.seed(seed)\n",
            "torch.manual_seed(seed)\n",
            "torch.cuda.manual_seed(seed)\n",
            "torch.backends.cudnn.deterministic = True"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Prepare the data\n",
            "\n",
            "We begin by tokenizing and cleaning the text. In this process, we'll remove punctuation, convert to lowercase, and remove stopwords. I believe that it's worth noting that removing stop words might be problematic in some model designs. For this particular model, which doesn't take into account word order, removing words like \"not\" should not affect the model's performance because the model won't have the capability of identifying where upon a given document the word \"not\" is located."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "# load the dataset\n",
            "train_data, test_data = load_dataset(\"yelp_polarity\", split=[\"train\", \"test\"])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# tokenize the dataset\n",
            "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
            "\n",
            "\n",
            "def tokenize(obs, tokenizer, max_length):\n",
            "    \"\"\"\n",
            "    Tokenize an observation\n",
            "    max_length: the maximum length of the tokenized sequence\n",
            "    \"\"\"\n",
            "    return {\"tokens\": tokenizer(obs[\"text\"])[:max_length]}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "# remove stopwords and punctuation\n",
            "stop_words = stopwords.words(\"english\")\n",
            "\n",
            "\n",
            "def remove_stopwords(obs):\n",
            "    \"\"\"\n",
            "    Removes stopwords from tokens for each obs in Dataset\n",
            "    \"\"\"\n",
            "    obs[\"tokens\"] = [word for word in obs[\"tokens\"] if word not in stop_words]\n",
            "    return obs\n",
            "\n",
            "\n",
            "def remove_punctuation(obs):\n",
            "    \"\"\"\n",
            "    Removes punctuation from tokens for each obs in Dataset\n",
            "    \"\"\"\n",
            "    obs[\"tokens\"] = [word for word in obs[\"tokens\"] if word.isalpha()]\n",
            "    return obs\n",
            "\n",
            "\n",
            "def tokenize_and_clean(obs, max_length):\n",
            "    \"\"\"\n",
            "    Tokenize, remove stopwords and punctuation from observation\n",
            "    \"\"\"\n",
            "    tokens = tokenizer(obs[\"text\"][:max_length])\n",
            "    tokens = [word for word in tokens if word not in stop_words]\n",
            "    tokens = [word for word in tokens if word.isalpha()]\n",
            "    return {\"tokens\": tokens}\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Working under the assumption that a document's sentiment can be identified rather quickly, I've set the maximum length of any given document to 100 words. This is a hyperparameter that can be adjusted to improve the model's performance."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "max_length = 100\n",
            "\n",
            "train_data = train_data.map(tokenize_and_clean, fn_kwargs={\"max_length\": max_length})\n",
            "test_data = test_data.map(tokenize_and_clean, fn_kwargs={\"max_length\": max_length})"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now that our data has been tokenized and cleaned, we can create a validation set. This validation set will allow us to monitor the model's performance during training with the objective of avoiding overfitting."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "# validation data\n",
            "train_valid_data = train_data.train_test_split(test_size=0.25)\n",
            "train_data = train_valid_data[\"train\"]\n",
            "valid_data = train_valid_data[\"test\"]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "From the training data, we now proceed to create a vocabulary comprised of the training data's unique words. Given the large number of documents in the training set, I'll add a minimum frequency threshold of 30 times for every word to be included in the vocabulary. Given the large number of observations we have available, removing words that appear only a few times should not affect the model's performance and should help remove some of the noise.\n",
            "\n",
            "Also very important in the creation of our vocabulary is to add a couple of special tokens: one for padding and one for unknown words. The padding token will be used to make all documents the same length, and the unknown token will be used to catch words that are not in the vocabulary."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "7827"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# creating the vocabulary\n",
            "special_tokens = [\"<unk>\", \"<pad>\"]\n",
            "\n",
            "# setting a minimum frequency for the tokens ... 30 times in 420,000 sentences is negligible\n",
            "vocab = torchtext.vocab.build_vocab_from_iterator(\n",
            "    train_data[\"tokens\"], specials=special_tokens, min_freq=30\n",
            ")\n",
            "vocab.set_default_index(vocab[\"<unk>\"])\n",
            "len(vocab)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We now have a vocabulary of 7,827 unique words (including the special tokens). The Vocab object has a method that is used to identify unknown words and replace them with the unknown token. We utilize that method to assign the index of \"unk\".\n",
            "\n",
            "Now that we have the vocabulary, we can numerically encode the words in the data using indices from the vocabulary we just created. We also need to pad the sequences so that they're all the same length and we don't run into issues when inputting them into the model."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "def numericalize_example(obs, vocab):\n",
            "    ids = vocab.lookup_indices(obs[\"tokens\"])\n",
            "    return {\"ids\": ids}\n",
            "\n",
            "\n",
            "train_data = train_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
            "valid_data = valid_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
            "test_data = test_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "train_data = train_data.with_format(\"torch\", columns=[\"ids\", \"label\"])\n",
            "valid_data = valid_data.with_format(\"torch\", columns=[\"ids\", \"label\"])\n",
            "test_data = test_data.with_format(\"torch\", columns=[\"ids\", \"label\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We're going to make use of data loaders. This will allow us to load the data in batches, which will be useful for training the model. This is where we'll use the padding process mentioned above. In this process we need to adequately structure the data so that it can be input into the model. We'll make use of a collate function to do this. Since we're working with PyTorch, we'll create a single tensor for each batch of data and a single tensor for the labels. Note that the data tensor will have a shape of (batch_size, max_length) and the labels tensor will have a shape of (batch_size, 1)."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "pad_index = vocab[\"<pad>\"]\n",
            "\n",
            "\n",
            "def get_collate_fn(pad_index):\n",
            "    def collate_fn(batch):\n",
            "        batch_ids = [doc[\"ids\"] for doc in batch]\n",
            "        batch_ids = nn.utils.rnn.pad_sequence(\n",
            "            batch_ids, padding_value=pad_index, batch_first=True\n",
            "        )\n",
            "        batch_labels = [doc[\"label\"] for doc in batch]\n",
            "        batch_labels = torch.stack(batch_labels)\n",
            "        return {\"ids\": batch_ids, \"label\": batch_labels}\n",
            "\n",
            "    return collate_fn\n",
            "\n",
            "\n",
            "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
            "    collate_fn = get_collate_fn(pad_index)\n",
            "    data_loader = torch.utils.data.DataLoader(\n",
            "        dataset=dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=shuffle\n",
            "    )\n",
            "    return data_loader"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now we shall set the batch size and create the data loaders for the training, validation and test sets."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "batch_size = 256\n",
            "\n",
            "train_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
            "valid_loader = get_data_loader(valid_data, batch_size, pad_index, shuffle=False)\n",
            "test_loader = get_data_loader(test_data, batch_size, pad_index, shuffle=False)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Building the model\n",
            "\n",
            "PyTorch's architecture allows us to specifically define how the model flows through the different layers. We begin by defining an Embedding layer. Knowing full well that modern NLP models have multiple features, I'll posit that the features required for sentiment analysis are not as complex as those required for other tasks. For that reason, I'll set the embedding dimension to 20. This is a hyperparameter that can be adjusted to improve the model's performance. The output from the embedding layer will be averaged across the sequence dimension. This will result in a single *feature* vector for each document. A *sigmoid* activation function is then applied to the feature vector. This feature vector is then passed through a fully connected layer, which maps the feature vector to the output space which consists of logits corresponding to the two sentiment classes. \n",
            "\n",
            " "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "class Sentiment(nn.Module):\n",
            "    def __init__(self, vocab_size, embed_dim, pad_index):\n",
            "        super(Sentiment, self).__init__()\n",
            "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_index)\n",
            "        self.fc = nn.Linear(embed_dim, 2)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.embedding(x)\n",
            "        x = x.mean(dim=1)\n",
            "        x = torch.sigmoid(x)\n",
            "        x = self.fc(x)\n",
            "\n",
            "        return x"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [],
         "source": [
            "vocab_size = len(vocab)\n",
            "embed_dim = 20\n",
            "\n",
            "model = Sentiment(vocab_size, embed_dim, pad_index)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "As explained previously, we'll use the Cross Entropy Loss function. We'll make use of PyTorch's built-in CrossEntropyLoss function. As noted above, we'll use the Adam optimizer to minimize our chosen loss function. We'll set the learning rate to 0.01, which is a hyperparameter that can be adjusted to improve the model's performance.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [],
         "source": [
            "# loss function and optimizer\n",
            "criterion = nn.CrossEntropyLoss()\n",
            "optimizer = optim.Adam(model.parameters(), lr=0.001)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "When available, we'll use the GPU to train the model. A GPU is a great asset when the training process can be parallelized, as is the case with neural networks. We'll use PyTorch's built-in device function to check if a GPU is available and set the device accordingly."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "cpu\n"
               ]
            }
         ],
         "source": [
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(device)\n",
            "model = model.to(device)\n",
            "criterion = criterion.to(device)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Of particular note in the following training process is the optimization process. As stated above, gradient descent first flows through each layer of the model, then works its way back while calculating the gradients at each step. This process is called backpropagation. Again, PyTorch's built-in architecture allows us to easily perform this process."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [],
         "source": [
            "# training the model\n",
            "def train(data_loader, model, criterion, optimizer, device):\n",
            "    model.train()\n",
            "    epoch_losses = []\n",
            "    epoch_accuracies = []\n",
            "    for batch in tqdm.tqdm(data_loader, desc=\"Training...\"):\n",
            "        ids = batch[\"ids\"].to(device)\n",
            "        label = batch[\"label\"].to(device)\n",
            "        prediction = model(ids)\n",
            "        loss = criterion(prediction, label)\n",
            "        accuracy = (prediction.argmax(1) == label).sum().item() / len(label)\n",
            "        optimizer.zero_grad()\n",
            "        loss.backward()\n",
            "        optimizer.step()\n",
            "        epoch_losses.append(loss.item())\n",
            "        epoch_accuracies.append(accuracy)\n",
            "    return np.mean(epoch_losses), np.mean(epoch_accuracies)\n",
            "\n",
            "\n",
            "# validation\n",
            "def evaluate(data_loader, model, criterion, device):\n",
            "    model.eval()\n",
            "    epoch_losses = []\n",
            "    epoch_accuracies = []\n",
            "    with torch.no_grad():\n",
            "        for batch in tqdm.tqdm(data_loader, desc=\"Evaluating...\"):\n",
            "            ids = batch[\"ids\"].to(device)\n",
            "            label = batch[\"label\"].to(device)\n",
            "            prediction = model(ids)\n",
            "            loss = criterion(prediction, label)\n",
            "            accuracy = (prediction.argmax(1) == label).sum().item() / len(label)\n",
            "            epoch_losses.append(loss.item())\n",
            "            epoch_accuracies.append(accuracy)\n",
            "    return np.mean(epoch_losses), np.mean(epoch_accuracies)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1641/1641 [00:23<00:00, 69.35it/s]\n",
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:06<00:00, 89.58it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 0\n",
                  "Train Loss: 0.6334, Train Accuracy: 0.6755\n",
                  "Valid Loss: 0.5422, Valid Accuracy: 0.7459\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1641/1641 [00:23<00:00, 69.12it/s]\n",
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:06<00:00, 87.82it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 1\n",
                  "Train Loss: 0.4992, Train Accuracy: 0.7613\n",
                  "Valid Loss: 0.4786, Valid Accuracy: 0.7673\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1641/1641 [00:23<00:00, 69.88it/s]\n",
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:06<00:00, 87.01it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 2\n",
                  "Train Loss: 0.4655, Train Accuracy: 0.7760\n",
                  "Valid Loss: 0.4628, Valid Accuracy: 0.7751\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1641/1641 [00:24<00:00, 68.29it/s]\n",
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:06<00:00, 82.40it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 3\n",
                  "Train Loss: 0.4532, Train Accuracy: 0.7822\n",
                  "Valid Loss: 0.4557, Valid Accuracy: 0.7791\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1641/1641 [00:24<00:00, 65.82it/s]\n",
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:06<00:00, 78.72it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 4\n",
                  "Train Loss: 0.4468, Train Accuracy: 0.7858\n",
                  "Valid Loss: 0.4527, Valid Accuracy: 0.7801\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1641/1641 [00:24<00:00, 66.06it/s]\n",
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:06<00:00, 89.64it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 5\n",
                  "Train Loss: 0.4428, Train Accuracy: 0.7880\n",
                  "Valid Loss: 0.4506, Valid Accuracy: 0.7816\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1641/1641 [00:23<00:00, 71.25it/s]\n",
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:06<00:00, 88.94it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 6\n",
                  "Train Loss: 0.4403, Train Accuracy: 0.7896\n",
                  "Valid Loss: 0.4490, Valid Accuracy: 0.7828\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1641/1641 [00:24<00:00, 66.33it/s]\n",
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:06<00:00, 82.84it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 7\n",
                  "Train Loss: 0.4385, Train Accuracy: 0.7902\n",
                  "Valid Loss: 0.4485, Valid Accuracy: 0.7834\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1641/1641 [00:23<00:00, 69.30it/s]\n",
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:06<00:00, 88.69it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 8\n",
                  "Train Loss: 0.4371, Train Accuracy: 0.7911\n",
                  "Valid Loss: 0.4481, Valid Accuracy: 0.7834\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1641/1641 [00:23<00:00, 69.94it/s]\n",
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:06<00:00, 87.91it/s] "
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch: 9\n",
                  "Train Loss: 0.4360, Train Accuracy: 0.7917\n",
                  "Valid Loss: 0.4476, Valid Accuracy: 0.7835\n",
                  "\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n"
               ]
            }
         ],
         "source": [
            "n_epochs = 10\n",
            "best_valid_loss = float(\"inf\")\n",
            "\n",
            "metrics = collections.defaultdict(list)\n",
            "\n",
            "for epoch in range(n_epochs):\n",
            "    train_loss, train_accuracy = train(\n",
            "        train_loader, model, criterion, optimizer, device\n",
            "    )\n",
            "    valid_loss, valid_accuracy = evaluate(valid_loader, model, criterion, device)\n",
            "    print(f\"Epoch: {epoch}\")\n",
            "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
            "    print(f\"Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n",
            "    print()\n",
            "    metrics[\"train_loss\"].append(train_loss)\n",
            "    metrics[\"train_accuracy\"].append(train_accuracy)\n",
            "    metrics[\"valid_loss\"].append(valid_loss)\n",
            "    metrics[\"valid_accuracy\"].append(valid_accuracy)\n",
            "\n",
            "    if valid_loss < best_valid_loss:\n",
            "        best_valid_loss = valid_loss\n",
            "        torch.save(model.state_dict(), \"best_model.pt\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Model Assesment\n",
            "\n",
            "Now that the validation process has completed, we can assess the model's performance. By design, we stored the model at the point where the training process resulted in the lowest validation loss with the objective of avoiding overfitting. That is the model that we're going to test on our held out test set."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<All keys matched successfully>"
                  ]
               },
               "execution_count": 19,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "model = Sentiment(vocab_size, embed_dim, pad_index)\n",
            "model.load_state_dict(torch.load(\"best_model.pt\"))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:02<00:00, 62.73it/s]"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Test Loss: 0.4432, Test Accuracy: 0.787%\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n"
               ]
            }
         ],
         "source": [
            "test_loss, test_acc = evaluate(test_loader, model, criterion, device)\n",
            "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.3f}%\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Our model had a testing accuracy to 79%. By itself, this number doesn't tell us much other than the fact that it adds considerable value to a random approach. The distribution of true labels in our data is 50/50. That is considerable value-added by this model. Additionally, we must explore how balanced the model's predictions are by assessing its errors."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Lists to store the predicted and true labels\n",
            "predicted_labels = []\n",
            "true_labels = []\n",
            "\n",
            "# Iterate over the test data\n",
            "for batch in test_loader:\n",
            "    # Move the data and labels to the same device as your model (if not already)\n",
            "    data = batch[\"ids\"].to(device)\n",
            "    labels = batch[\"label\"].to(device)\n",
            "\n",
            "    # Make a prediction\n",
            "    with torch.no_grad():\n",
            "        outputs = model(data)\n",
            "\n",
            "    # Get the predicted class\n",
            "    _, preds = torch.max(outputs, 1)\n",
            "\n",
            "    # Store the predicted and true labels\n",
            "    predicted_labels.extend(preds.cpu().numpy())\n",
            "    true_labels.extend(labels.cpu().numpy())\n",
            "\n",
            "# Convert the lists to numpy arrays\n",
            "predicted_labels = np.array(predicted_labels)\n",
            "true_labels = np.array(true_labels)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Text(0.5, 1.0, 'Confusion Matrix')"
                  ]
               },
               "execution_count": 22,
               "metadata": {},
               "output_type": "execute_result"
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 2 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# confusion matrix heatmap with seaborn\n",
            "cm = confusion_matrix(true_labels, predicted_labels)\n",
            "ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
            "ax.set_xlabel(\"Predicted labels\")\n",
            "ax.set_ylabel(\"True labels\")\n",
            "ax.set_title(\"Confusion Matrix\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Precision: 0.78\n",
                  "Recall: 0.79\n"
               ]
            }
         ],
         "source": [
            "# precision: out of all the predicted positive classes, how many were actually positive\n",
            "precision = np.sum(cm[1, 1]) / (np.sum(cm[1, 1]) + np.sum(cm[0, 1]))\n",
            "print(\"\\nPrecision: {:.2f}\".format(precision))\n",
            "\n",
            "# recall: out of all the actual positive classes, how many were predicted positive\n",
            "recall = np.sum(cm[1, 1]) / (np.sum(cm[1, 1]) + np.sum(cm[1, 0]))\n",
            "print(\"Recall: {:.2f}\".format(recall))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "From the above results we can conclude that our model is very well balanced in its predictions.\n",
            "\n",
            "Overall, these initial results are quite promising. As we explained throughout the process, there are still a few hyperparameters that can be adjusted to improve the model's performance. Additionally, we shall explore ways of adding more context to our embeddings by finding a way to include word order."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Further considerations\n",
            "\n",
            "One of our objectives was to create word embeddings specific to sentiment analysis. Arguably, we can use the word embeddings learned in this process for sentiment analysis on similar datasets. Let's see a couple of embeddings examples to see if we can extract any insights from them:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [],
         "source": [
            "# add embeddings to vocab\n",
            "embeddings = model.embedding.weight.detach().cpu().numpy()\n",
            "word_to_embedding = {word: embeddings[i] for word, i in vocab.get_stoi().items()}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Comparing fantastic and terrible: -202.92\n",
                  "Comparing fantastic and phenomenal: 124.73\n",
                  "Comparing fantastic and great: 82.63\n",
                  "Comparing fantastic and bad: -49.91\n",
                  "Comparing terrible and bad: 83.04\n",
                  "Comparing fantastic and dog: 0.39\n"
               ]
            }
         ],
         "source": [
            "def compare_embeddings(word1, word2):\n",
            "    \"\"\"\n",
            "    Compare the embeddings of two words\n",
            "    \"\"\"\n",
            "    if word1 not in word_to_embedding:\n",
            "        word1 = \"<unk>\"\n",
            "    if word2 not in word_to_embedding:\n",
            "        word2 = \"<unk>\"\n",
            "\n",
            "    print(\n",
            "        f\"Comparing {word1} and {word2}: {np.dot(word_to_embedding[word1], word_to_embedding[word2]):.2f}\"\n",
            "    )\n",
            "\n",
            "\n",
            "compare_embeddings(\"fantastic\", \"terrible\")\n",
            "compare_embeddings(\"fantastic\", \"phenomenal\")\n",
            "compare_embeddings(\"fantastic\", \"great\")\n",
            "compare_embeddings(\"fantastic\", \"bad\")\n",
            "compare_embeddings(\"terrible\", \"bad\")\n",
            "compare_embeddings(\"fantastic\", \"dog\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "From the above results we can gather some intuition into some of the relationships that were learned: We would expect that words that convey similar sentiment would have similar embeddings (and therefore a positive dot product). Words that convey sentiment in the same direction but with different intensity would be positive but with a lower dot product. Words that convey sentiment in the opposite direction would have a negative dot product. Finally, comparing a word with sentimental value to a word with no sentimental value should result in a dot product close to zero."
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "base",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.12"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
